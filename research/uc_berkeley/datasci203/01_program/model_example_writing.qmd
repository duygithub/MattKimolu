---
title: "Explanatory Linear Model Framework for Optimal Breaststroke Stroke Count in Different Competitive Swimming Scenarios"
format: pdf
editor: source
toc: true
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}



# List of required packages
required_packages <- c(
  "ggplot2", "readr", "dplyr", "tidyr", "tidyverse", 
  "rmarkdown", "here", "emmeans", "readxl", "data.table"
)

# Function to check and install missing packages
install_if_missing <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg, dependencies = TRUE)
      library(pkg, character.only = TRUE)
    }
  }
}

# Call the function to install and load the necessary packages
install_if_missing(required_packages)


```

```{r simulate data, echo=FALSE, message=FALSE, warning=FALSE}



## function for simulate raw data

simulate_data <- function(
    total_sample,
    elapsed_time_mean, elapsed_time_sd,
    stroke_count_mean, stroke_count_sd,
    data_entry_type_probability,
    seed = NULL
) {
  # ----- setup & validations -------------------------------------------------
  if (!is.null(seed)) set.seed(seed)
  
  # basic checks
  stopifnot(is.numeric(total_sample), length(total_sample) == 1, total_sample > 0)
  N <- as.integer(total_sample)
  
  stopifnot(is.numeric(elapsed_time_mean), is.numeric(elapsed_time_sd),
            length(elapsed_time_mean) == 1, length(elapsed_time_sd) == 1,
            elapsed_time_sd >= 0)
  
  stopifnot(is.numeric(stroke_count_mean), is.numeric(stroke_count_sd),
            length(stroke_count_mean) == 1, length(stroke_count_sd) == 1,
            stroke_count_sd >= 0)
  
  levels_det <- c("25", "50L1", "50L2", "100IM")
  
  # probabilities: allow named or unnamed vector of length 4
  stopifnot(length(data_entry_type_probability) == 4, is.numeric(data_entry_type_probability),
            all(is.finite(data_entry_type_probability)), all(data_entry_type_probability >= 0))
  
  # if named, reorder to expected levels
  if (!is.null(names(data_entry_type_probability))) {
    missing_names <- setdiff(levels_det, names(data_entry_type_probability))
    if (length(missing_names))
      stop("data_entry_type_probability must contain names: ", paste(levels_det, collapse = ", "))
    data_entry_type_probability <- data_entry_type_probability[levels_det]
  }
  
  # must sum to 1 (within a tiny tolerance)
  if (abs(sum(data_entry_type_probability) - 1) > 1e-8) {
    stop("data_entry_type_probability must sum to 1. Current sum = ", sum(data_entry_type_probability))
  }
  
  # ----- generate variables --------------------------------------------------
  # 1) event_ordinal: integer record id 1..N
  event_ordinal <- seq_len(N)
  
  # 2) elapsed_time: Normal(mean, sd), non-negative, 2 decimal places
  if (elapsed_time_sd == 0) {
    elapsed_time <- rep(elapsed_time_mean, N)
  } else {
    elapsed_time <- rnorm(N, mean = elapsed_time_mean, sd = elapsed_time_sd)
  }
  elapsed_time <- round(pmax(elapsed_time, 0), 2)
  
  # 3) stroke_count: Normal(mean, sd) -> integer, non-negative
  if (stroke_count_sd == 0) {
    stroke_count <- rep(stroke_count_mean, N)
  } else {
    stroke_count <- rnorm(N, mean = stroke_count_mean, sd = stroke_count_sd)
  }
  stroke_count <- as.integer(round(pmax(stroke_count, 0), 0))
  
  # 4) data_entry_type: categorical with specified probs
  data_entry_type <- factor(
    sample(levels_det, size = N, replace = TRUE, prob = data_entry_type_probability),
    levels = levels_det
  )
  
  # ----- assemble & return ---------------------------------------------------
  data.frame(
    event_ordinal = as.integer(event_ordinal),
    elapsed_time = elapsed_time,
    stroke_count = stroke_count,
    data_entry_type = data_entry_type,
    stringsAsFactors = FALSE
  )
}


### Example test run:

dat <- simulate_data(
  total_sample = 1000,
  elapsed_time_mean = 20, elapsed_time_sd = 4,
  stroke_count_mean = 16, stroke_count_sd = 3,
  data_entry_type_probability = c("25"=0.25, "50L1"=0.25, "50L2"=0.25, "100IM"=0.25),
  seed = 203
)

head(dat)
table(dat$data_entry_type)


dat$data_entry_type<- as.character(dat$data_entry_type)
write.csv(dat,here(
                   "simulated_raw_data1.csv"),
          row.names = FALSE)


```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


dat<- read.csv(here("simulated_raw_data1.csv"))


dat$data_entry_type <- factor(dat$data_entry_type,
                              levels = c("25", "50L2", "50L1", "100IM"))



model2 <- lm(elapsed_time ~ stroke_count + data_entry_type + I(stroke_count^2) + stroke_count * data_entry_type , data =dat )
summary(model2)

##############################################

```

# Model

R formula:

elapsed_time \~ stroke_count + I(stroke_count\^2) + data_entry_type + stroke_count:data_entry_type

Mathematical form:

Let $y_i$ be elapsed_time}, $s_i$ be stroke_count, and $D^{50L2}_i, D^{50L1}_i, D^{100IM}_i$ indicate the data_entry_type:

$$

y_i = \beta_0 
+ \beta_1s_i 
+ \beta*2s^2_i 
+ \gamma_{50L2} D^{50L2}_i
+ \gamma_{50L1} D^{50L1}_i
+ \gamma_{100IM} D^{100IM}_i 
+ \delta_{50L2} (s_i D^{50L2}_i)
+ \delta_{50L1} (s_i D^{50L1}_i)
+ \delta_{100IM} (s_i D^{100IM}_i)
+ \varepsilon_i




$$



## Model interpretation

1, We are using data_entry_type = 25 as baseline.
2, Intercept $\beta_0$: expected time for the data_entry_type = 25 at stroke = 0.
3, Baseline stroke slope $\beta_1$:change in expected time per extra stroke for data_entry_type = 25 at stroke = 0.
4, Curvature $\beta_2$: common quadratic effect for all types.
5, Type intercept shifts $\gamma_k$: vertical shift of each type $ð‘˜$ relative to 25 when stroke = 0.
6, Type slope shifts $\delta_k$ : how the stroke slope differs for type $ð‘˜$ vs data_entry_type = 25.

## Predictive plots

```{r, echo=FALSE, message=FALSE, warning=FALSE}

## Predictive plot:

# grid of predictors to plot over
newdat <- expand.grid(
  stroke_count = seq(min(dat$stroke_count, na.rm = TRUE),
                     max(dat$stroke_count, na.rm = TRUE), length.out = 200),
  data_entry_type = unique(dat$data_entry_type)
)

# predictions + 95% CI
p <- predict(model2, newdata = newdat, se.fit = TRUE)
newdat <- newdat %>%
  mutate(fit = p$fit, se = p$se.fit,
         lwr = fit - 1.96*se, upr = fit + 1.96*se)

# plot: points + fitted curve + CI ribbon
ggplot(dat, aes(stroke_count, elapsed_time, color = data_entry_type)) +
  geom_point(alpha = 0.35, size = 1) +
  geom_ribbon(data = newdat,
              aes(y = fit, ymin = lwr, ymax = upr, fill = data_entry_type, color = NULL),
              alpha = 0.15) +
  geom_line(data = newdat, aes(y = fit), linewidth = 1) +
  labs(x = "Stroke count", y = "Elapsed time",
       title = "Fitted quadratic-with-interaction by data_entry_type") +
  theme_minimal()

```


## Residual plots

```{r, echo=FALSE, message=FALSE, warning=FALSE}



par(mfrow = c(2,2))
plot(model2, which = 1)  # Residuals vs Fitted (linearity/variance check)
plot(model2, which = 2)  # Normal Q-Q (normality check)
plot(model2, which = 3)  # Scale-Location (homoscedasticity)
plot(model2, which = 4)  # Residuals vs Leverage (influence)



```
