
# TFL Pipeline program


```{r Load all needed library}

# List of required packages
required_packages <- c(
  "ggplot2", "readr", "dplyr", "tidyr", "tidyverse", 
  "rmarkdown", "here", "emmeans", "readxl", "data.table",
 "parsedate", "mmrm", "patchwork",
  "rstudioapi",
 "units", "stargazer", "sandwich",
 "knitr", "modelsummary", "broom", "rlang",
 "MASS"
 
)

# Function to check and install missing packages
install_if_missing <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg, dependencies = TRUE)
      library(pkg, character.only = TRUE)
    }
  }
}

# Call the function to install and load the necessary packages
install_if_missing(required_packages)

# Set the encoding to UTF-8
Sys.setlocale("LC_CTYPE", "en_US.UTF-8")
#################################################################



```

```{r, setwd}

# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# current_path <- getwd()


```

```{r, process data}


source("source/compile_main_data.R")

data_files_names <- c("20251118_-8.csv", "20251121_-8.csv", "20251122_-8.csv", "20251129_-8.csv", "20251204_-8.csv", "20251208_-8.csv", "20251211_-8.csv","20251213_-8.csv")
main_data <- compile_data_files(data_files_names)
main_data_for_plotting <- prep_data_for_plotting(main_data)
main_data_for_modeling <- prep_data_for_modeling(main_data)




```

```{r, data}


main_data_for_modeling2 <- main_data_for_modeling%>%
  mutate(record_id = row_number(), .before = 1) %>%
  mutate(stroke_count_square = stroke_count ^2)
  


model_v4 <- lm(time_milliseconds ~ 
                stroke_count + 
                I(stroke_count^2) + 
                data_entry_type + 
                event_ordinal + 
                event_ordinal  * stroke_count +
                event_ordinal  *I(stroke_count^2)  , 
              data = main_data_for_modeling  )

summary(model_v4)



model_v0 <- lm(time_milliseconds ~ 
                data_entry_type + 
                event_ordinal,  
              data = main_data_for_modeling  )

summary(model_v0)


anova(model_v0,model_v4 )



```

```{r plot model 4}

# ##########################################################
## Plot Outlier,Leverage,Influential:
df <- main_data_for_modeling2
model <- model_v4
# Define color mapping
color_mapping <- c(
                   "25 or 50L1" = "blue",
                   "50L2" = "red",
                   "100IM" = "darkgreen")

# Convert unwell_feedback to factor for shape mapping
# df$unwell_feedback <- as.factor(df$unwell_feedback)

# # Define shape mapping
# shape_mapping <- c(  "Non-Outlier,Leverage,Influential" = 16,
#                      "Leverage Point"=3,
#                      "Influential Point"=4,
#                       "Outlier"=1
# 
# )

# scale_shape_manual(name="Point Status",values=c(
#     "Non-Outlier,Leverage,Influential"=16,
#     "Leverage Point"=3,
#     "Influential Point(diffit)"=4,
#     "Outlier"=1



# Create prediction data for each data_entry_type
stroke_range <- range(main_data_for_modeling2$stroke_count)
pred_data <- expand.grid(
  event_ordinal = seq(1, 1, length.out = 100),
  stroke_count = seq(stroke_range[1], stroke_range[2], length.out = 100),
  data_entry_type = unique(main_data_for_modeling2$data_entry_type)
)

# Get predictions with 95% confidence intervals
pred_results <- predict(model , newdata = pred_data, interval = "confidence", level = 0.95)
pred_data <- cbind(pred_data, pred_results)

# Plot with outliers
ggplot() +
  # Add 95% CI
  geom_ribbon(data = pred_data,
              aes(x = stroke_count,
                  ymin = lwr,
                  ymax = upr,
                  fill = data_entry_type),
              alpha = 0.2)+
  # Add prediction lines
  geom_line(data = pred_data,
            aes(x = stroke_count,
                y = fit,
                color = data_entry_type),
            linewidth = 1) +
  # Add scatter points
  geom_point(data = df,
             aes(x = stroke_count,
                 y = time_milliseconds,
                 color = data_entry_type),
             size = 3) +
  # Apply color scales
  scale_color_manual(values = color_mapping) +
  scale_fill_manual(values = color_mapping) +
  # Labels
  labs(x = "Stroke Count",
       y = "Time (milliseconds)",
       color = "Data Entry Type",
       fill = "Data Entry Type",
       shape = "Outlier Type") +
  theme_minimal()+
  scale_x_continuous(breaks = function(x) seq(floor(min(x)), ceiling(max(x)), by = 1))+
  # scale_y_continuous(breaks = function(y) seq(floor(min(y)/1000)*1000,
  #                                              ceiling(max(y)/1000)*1000,
  #                                              by = 1000))+
  scale_y_continuous(breaks = function(y) seq(24000,
                                               42000,
                                               by = 1000))+
  coord_cartesian(ylim = c(24000,42000))+
  theme(legend.position = "right")


```


```{r, variable selection}

library(leaps)
# ?regsubsets

df <- main_data_for_modeling2 %>%
  mutate(stroke_count_squre = stroke_count ^2,
         event_ordinal_square = event_ordinal ^2)

# all <- regsubsets(x=cbind(stroke_count,
#                           data_entry_type,
#                           unwell_feedback,
#                           event_ordinal), 
#                   y=time_milliseconds,  
#                   method = "exhaustive", 
#                   all.best = FALSE, 
#                   nbest = 6)

all <- regsubsets(time_milliseconds ~ 
                    (stroke_count + 
                    stroke_count_squre + 
                    data_entry_type + 
                    event_ordinal + 
                    event_ordinal_square +
                    unwell_feedback)^2 ,
                  data=df,
                  method = "exhaustive",
                  nvmax=20)


summary(all)
Cp <- summary(all)$cp # Mallows’s Cp Statistic: Models with small Cp values are desirable. Note, that we need a reliable estimate of σ2 to compute the Cp statistic. Often, the MSRes of the full model is used for this purpose.
AdjR2 <- summary(all)$adjr2
SSRes <- summary(all)$rss
R2 <- summary(all)$rsq
Matrix <- summary(all)$which

# Adding MSRes(Mean Squared Residuals)
p <- apply(Matrix,1, sum)
n <- nrow(df)
MSRes <- SSRes/(n-p)

# Make a nice table
output <- cbind(p, Matrix, SSRes, R2, AdjR2, MSRes, Cp)

output2 <- as.data.frame(output )

write.csv(output2, "test_variable_selection.csv", row.names = FALSE)

```
